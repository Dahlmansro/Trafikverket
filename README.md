# ğŸš† Trafikverket â€“ Bygga och analysera tÃ¥gresor

![Python](https://img.shields.io/badge/python-3.12-blue)
![License](https://img.shields.io/badge/license-MIT-green)


## ğŸ§­ ProjektÃ¶versikt

Detta projekt analyserar Trafikverkets Ã¶ppna tÃ¥gtrafikdata med syftet att identifiera vilka faktorer som pÃ¥verkar fÃ¶rseningar samt att bygga prediktiva modeller som kan fÃ¶rutsÃ¤ga sannolikheten att ett tÃ¥g blir fÃ¶rsenat. 

Projektet bestÃ¥r av en dataprocesspipeline som kÃ¶rs lokalt eller i Azure, och resultatet visualiseras i en Power BI-rapport. 
Fokus ligger pÃ¥ punktlighet enligt **RT+5** â€“ dvs. andelen tÃ¥g som ankommer inom 5 minuter och 59 sekunder efter planerad tid.

---

## ğŸ“‹ Krav fÃ¶re installation

### Systemkrav
- **Python 3.12** eller senare
- **Conda** eller **venv** fÃ¶r virtuell miljÃ¶
- **Git** fÃ¶r att klona repositoryt
- **Power BI Desktop** (fÃ¶r att Ã¶ppna visualiseringar)

### Azure-krav
- Ett aktivt **Azure-konto**
- **Azure Data Lake Storage Gen2** (fÃ¶r att lagra och hantera data)
- **Storage Account Key** med lÃ¤s- och skrivbehÃ¶righeter

### API-Ã¥tkomst
- **Trafikverkets API-nyckel** https://api.trafikinfo.trafikverket.se/

---

## ğŸ§© DatakÃ¤llor

- **Trafikverket Open API** â€“ data om avgÃ¥ngar och ankomster (TrainAnnouncement)
- **Azure Data Lake Storage** â€“ lagring av rÃ¥-, bearbetad och berikad data (parquet-format)
- **station_info.parquet** â€“ metadata om stationer, lÃ¤n och koordinater

---

## âš™ï¸ Installation och konfiguration

### Skapa miljÃ¶
```bash
conda create -n trafikverket_env python=3.12 -y
conda activate trafikverket_env
```

### Installera beroenden
```bash
pip install -r requirements.txt
```

### MiljÃ¶variabler (.env)
Skapa en fil `.env` i projektroten med fÃ¶ljande nycklar:
```
ACCOUNT_URL=https://<ditt_storagekonto>.dfs.core.windows.net
CONTAINER_NAME=trafikdata
STORAGE_ACCOUNT_KEY=<din_azure_nyckel>
TRAFIKVERKET_API_KEY=<din_trafikverket_api_nyckel>
```

## â–¶ï¸ KÃ¶rning av pipeline

Pipeline-skriptet `process_trips.py` hÃ¤mtar, bearbetar och sparar resdata till Azure Data Lake.

### Exempel: kÃ¶r senaste tvÃ¥ dagarna
```bash
cd pipeline
python process_trips.py
```

### Exempel: kÃ¶r specifika datum
```bash
python process_trips.py --dates 20241020 20241021
```

### Exempel: kÃ¶r alla tillgÃ¤ngliga raw-filer
```bash
python process_trips.py --all
```
### TrÃ¤na och utvÃ¤rdera maskininlÃ¤rningsmodeller

**Ã–ppna notebooks i `ml_modell/`:**

```bash
cd ml_modell
jupyter notebook
```

**KÃ¶r notebooks i fÃ¶ljande ordning:**

1. **`1_0_Load_and_Clean_Data.ipynb`**  
   Laddar data frÃ¥n Azure och fÃ¶rbereder den fÃ¶r modelltrÃ¤ning.

2. **`2_0_Delay_Prediction_Model.ipynb`**  
   TrÃ¤nar fyra klassificeringsmodeller: Logistic Regression, Random Forest, Gradient Boosting och XGBoost.  
   UtvÃ¤rderar modellerna med accuracy, precision, recall, F1-score och ROC-AUC.

3. **`3_0_Evaluate_predictions.ipynb`**  
   Validerar den bÃ¤sta modellen pÃ¥ planerade resor och analyserar feature importance.

```

## Filstruktur

Trafikverket/
â”‚
â”œâ”€â”€ ml_modell/                                # MaskininlÃ¤rningsmodeller och analys
â”‚   â”œâ”€â”€ data/                                # Lokal datakatalog
â”‚   â”œâ”€â”€ predictions/                         # Modellprediktioner
â”‚   â”œâ”€â”€ validation/                          # Valideringsdata
â”‚   â”œâ”€â”€ 1_0_Load_and_Clean_Data.ipynb        # Notebook: DatafÃ¶rbearbetning
â”‚   â”œâ”€â”€ 2_0_Delay_Prediction_Model.ipynb     # Notebook: ModelltrÃ¤ning
â”‚   â”œâ”€â”€ 3_0_Evaluate_predictions.ipynb       # Notebook: ModellutvÃ¤rdering
â”‚   â”œâ”€â”€ train_delay_encoder.pkl              # TrÃ¤nad encoder
â”‚   â”œâ”€â”€ train_delay_model.pkl                # TrÃ¤nad modell
â”‚   â”œâ”€â”€ train_delay_scaler.pkl               # TrÃ¤nad scaler
â”‚   â””â”€â”€ training_feature_names.json          # Feature-namn fÃ¶r trÃ¤ning
â”‚
â”œâ”€â”€ pipeline/                                # Data-pipeline fÃ¶r ETL
â”‚   â”œâ”€â”€ logs/                                # Automatiskt genererade loggar
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                            # Konfiguration (API, Azure)
â”‚   â”œâ”€â”€ logger.py                            # Centraliserad loggningsmodul
â”‚   â”‚
â”‚   â”œâ”€â”€ fetch_train_data.py                  # Steg 1: HÃ¤mta historisk data
â”‚   â”œâ”€â”€ fetch_planned.py                     # Steg 2: HÃ¤mta planerad data
â”‚   â”œâ”€â”€ process_trips.py                     # Steg 3: Processera trips
â”‚   â”œâ”€â”€ transform_planned_to_curated.py      # Steg 4: Transformera planerad
â”‚   â”œâ”€â”€ combine_all_trips.py                 # Steg 5: Kombinera alla trips
â”‚   â”œâ”€â”€ run_production_pipeline.py           # Huvudscript fÃ¶r pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ inspect_combined_total.ipynb         # Inspektion: Historisk data
â”‚   â”œâ”€â”€ inspect_planned.ipynb                # Inspektion: Planerad data
â”‚   â”‚
â”‚   â”œâ”€â”€ station_info.parquet                 # Stationsmetadata
â”‚   â”œâ”€â”€ requirements.txt                     # Python-beroenden
â”‚   â”œâ”€â”€ .gitignore                           # Git ignore-regler
â”‚   â””â”€â”€ .funcignore                          # Azure Functions ignore
â”‚
â”œâ”€â”€ README.md                                # Huvuddokumentation
â”œâ”€â”€ requirements.txt                         # Projektets dependencies
â”œâ”€â”€ .gitignore                               # Git ignore fÃ¶r hela projektet
â””â”€â”€ trafikverket.pbix                        # Power BI-rapport
```
### Pipeline-flÃ¶de

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1ï¸âƒ£ HÃ„MTA DATA (fetch_train_data.py)                        â”‚
â”‚     Trafikverket API â†’ Azure/raw/                           â”‚
â”‚     â”œâ”€ departures_YYYYMMDD.parquet                          â”‚
â”‚     â””â”€ arrivals_YYYYMMDD.parquet                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2ï¸âƒ£ HÃ„MTA PLANERAD (fetch_planned.py)                       â”‚
â”‚     Trafikverket API â†’ Azure/raw/planned/                   â”‚
â”‚     â”œâ”€ arrivals_YYYY-MM-DD.json                             â”‚
â”‚     â””â”€ departures_YYYY-MM-DD.json                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3ï¸âƒ£ PROCESSERA RESOR (process_trips.py)                     â”‚
â”‚     Azure/raw/ â†’ Azure/curated/                             â”‚
â”‚     â”œâ”€ Platta ut nÃ¤stlade JSON-strukturer                   â”‚
â”‚     â”œâ”€ Gruppera per tÃ¥g + datum                             â”‚
â”‚     â”œâ”€ Matcha avgÃ¥ngar med ankomster                        â”‚
â”‚     â”œâ”€ BerÃ¤kna fÃ¶rseningar & avstÃ¥nd                        â”‚
â”‚     â””â”€ trips_combined_YYYYMMDD.parquet                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4ï¸âƒ£ TRANSFORMERA PLANERAD (transform_planned_to_curated.py)â”‚
â”‚     Azure/raw/planned/ â†’ Azure/curated/planned/             â”‚
â”‚     â””â”€ planned_trips_YYYY-MM-DD.parquet                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5ï¸âƒ£ KOMBINERA ALLA (combine_all_trips.py)                   â”‚
â”‚     SlÃ¥ ihop alla resor â†’ En huvudfil                       â”‚
â”‚     â”œâ”€ Deduplicera pÃ¥ (TrainIdent, Date)                    â”‚
â”‚     â””â”€ trips_combined_total.parquet                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Dataprocess och skapande av resor

Resorna skapas automatiskt utifrÃ¥n Trafikverkets Ã¶ppna trafikdata. Projektet Ã¤r uppbyggt som en tydlig pipeline som hÃ¤mtar, bearbetar och lagrar data i Azure Data Lake innan den visualiseras i Power BI.

```
RAW-data (ankomster + avgÃ¥ngar)
       â†“
LÃ¤s in Parquet-filer frÃ¥n Azure Data Lake
   â†’ raw/departures_YYYYMMDD.parquet
   â†’ raw/arrivals_YYYYMMDD.parquet
       â†“
Platta ut nÃ¤stlade kolumner (FromLocation, ToLocation, TypeOfTraffic)
Konvertera tidkolumner till UTC-format
Tilldela datum (TripDate)
       â†“
Gruppera per tÃ¥g och datum
   â†’ AdvertisedTrainIdent + TripDate
       â†“
FÃ¶r varje grupp:
   â†’ Identifiera fÃ¶rsta avgÃ¥ngen  (ActivityType = departure)
   â†’ Identifiera sista ankomsten  (ActivityType = arrival)
       â†“
BerÃ¤kna:
   â†’ FÃ¶rsening i minuter
   â†’ Restid, operatÃ¶r, typ av trafik, veckodag, mÃ¥nad, timme
       â†“
Berika med stationsdata (station_info.parquet)
   â†’ Namn, lÃ¤n, koordinater, avstÃ¥nd i km (haversine)
       â†“
Spara resultatet till Azure Data Lake (curated/)
   â†’ trips_combined_YYYYMMDD.parquet
   â†’ trips_combined_YYYYMMDD_canceled.parquet
```

### Definition av is_delayed
En resa markeras som fÃ¶rsenad (`is_delayed = 1`) om tÃ¥get anlÃ¤nder **mer Ã¤n 5 minuter och 59 sekunder (RT+5)** efter planerad ankomsttid. Annars markeras resan som punktlig (`is_delayed = 0`).

---

## ğŸ“Š Power BI-visualisering

Nyckeltal och statistik Ã¶ver det fÃ¤rdiga datamaterialet visualiseras i en **Power BI-rapport** som Ã¤ven finns publicerad i projektets Git-repo. Rapporten visar bland annat:
- Punktlighet (RT+5)
- FÃ¶rseningar per operatÃ¶r och lÃ¤n
- TidsmÃ¶nster (dygn, veckodag, mÃ¥nad)
- Geografisk spridning av fÃ¶rseningar

FÃ¶r att visa rapporten:
1. Ã–ppna `trafikverket.pbix` i Power BI Desktop
2. Kontrollera att datakÃ¤llan pekar mot rÃ¤tt mapp (`curated/`)
3. Uppdatera data med **Refresh**

---

## ğŸ¤– MaskininlÃ¤rning

Den bearbetade datan anvÃ¤nds som underlag fÃ¶r maskininlÃ¤rningsmodeller som trÃ¤nas fÃ¶r att fÃ¶rutsÃ¤ga sannolikheten att ett tÃ¥g blir fÃ¶rsenat. Modellerna testas med flera olika algoritmer, bland annat:
- **Logistic Regression**
- **Random Forest**
- **Gradient Boosting**
- **XGBoost**

Varje modell utvÃ¤rderas med mÃ¥tt som *accuracy*, *precision*, *recall*, *F1-score* och *ROC-AUC* fÃ¶r att bedÃ¶ma hur vÃ¤l de identifierar faktiska fÃ¶rseningar. Resultaten jÃ¤mfÃ¶rs sedan fÃ¶r att vÃ¤lja den modell som ger bÃ¤st balans mellan precision och generaliseringsfÃ¶rmÃ¥ga.

**Resultat:**
- XGBoost uppnÃ¥dde bÃ¤st prestanda med 81% accuracy och 0.53 recall pÃ¥ historisk testdata
- Vid validering pÃ¥ planerade resor sjÃ¶nk recall till 0.18, vilket visar begrÃ¤nsningar i generaliseringsfÃ¶rmÃ¥gan
- Analysen bekrÃ¤ftar att lÃ¤ngre distanser, dagtid och vardagar Ã¶kar fÃ¶rseningsrisken

---

## ğŸ‘¥ Projektteam

**Camilla Dahlman**, **Karl TengstrÃ¶m**, **Gustav Jeansson**  
Data Scientists (EC Utbildning)  

FÃ¶r kontakt, se respektive LinkedIn-profil.

---

Detta projekt anvÃ¤nder Trafikverkets Ã¶ppna data enligt gÃ¤llande anvÃ¤ndarvillkor.